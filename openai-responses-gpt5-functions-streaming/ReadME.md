# OpenAI *Responses* API â€” GPT-5 Function Calls + Streaming

This recipe shows how to use **OpenAIâ€™s experimental `responses` endpoint** with

- â© **Server-side streaming** (no latency between tokens)
- ğŸ”§ **Function calling** (tools) with a multi-step loop
- ğŸ’¾ Conversation continuity via **`previous_response_id`**
- ğŸ–¼ï¸ A Chainlit debug step that prints the **full conversation history**
- ğŸ—ƒï¸ Simple in-memory cache for tool outputs (O(1) lookup)

It answers in classic *Ned Flanders* style just for funâ€”feel free to tweak the `instructions` string in `app.py`.

---

## Quick-start

```bash
# 1. Install deps into a fresh venv (optional but recommended)
python -m venv .venv
source .venv/bin/activate       # or .\.venv\Scripts\activate on Windows
pip install -r requirements.txt

# 2. Export your key (or create a .env file that Chainlit will pick up)
export OPENAI_API_KEY=<your key>

# 3. Run the app
chainlit run app.py -w
